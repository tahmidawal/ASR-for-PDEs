# FNO-1D Advanced Configuration: ~120-150K parameters
#
# Enhanced Fourier Neural Operator with all optimizations
# Architecture: 6-layer FNO with 32 modes and 96 channels
# Features:
#   - Higher frequency resolution (32 modes vs 16)
#   - Deeper network (6 layers vs 4)
#   - Wider channels (96 vs 64)
#   - Residual connections between FNO layers
#   - Learnable frequency importance weights
#   - Layer normalization for training stability
#
# Expected performance: 0.001-0.05% relative L2 error
# This is the most powerful model, designed to push towards 0.01% target
#

train_dataset:
  dataset:
    name: poisson1d-synthetic
    args:
      num_samples: 10000
      resolution: 256
      freq_range: [1, 20]
      use_superposition: true
      num_components: 5
      use_float64: true
      normalize_solution: true
      seed: 42
  batch_size: 32

val_dataset:
  dataset:
    name: poisson1d-synthetic
    args:
      num_samples: 2000
      resolution: 256
      freq_range: [1, 20]
      use_superposition: true
      num_components: 5
      use_float64: true
      normalize_solution: true
      seed: 12345
  batch_size: 32

model:
  name: fno-1d-advanced
  args:
    modes: 32
    width: 96
    num_layers: 6
    activation: gelu
    use_layer_norm: true
    use_freq_weights: true

optimizer:
  name: adam
  args:
    lr: 3.0e-4
    betas: [0.9, 0.999]
    weight_decay: 1.0e-6

epoch_max: 1500
epoch_val: 1
early_stopping_patience: 100

reduce_lr_on_plateau:
  mode: min
  factor: 0.5
  patience: 25
  threshold: 1.0e-10
  min_lr: 1.0e-9
  cooldown: 5
  verbose: true

grad_clip: 1.0
use_double_precision: true
loss_type: l2  # Use L2 loss instead of MSE
